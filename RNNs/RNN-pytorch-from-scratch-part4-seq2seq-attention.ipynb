{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq model with Bahdanau attention\n",
    "在这个notebook当中，我会先不尝试参考开源方案，然后采取自己先思考的模式，尝试将代码写出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq知识点总结\n",
    "\n",
    "- 结构：\n",
    "    - 1. encoder: BiLSTM模型\n",
    "    - 2. decoder：BiLSTM模型\n",
    "\n",
    "- 训练过程\n",
    "    - 1. encoder部分：假设有输入英文序列 X = [\"<SOS>\",\"I\",\"Love\",\"You\",\"<EOS>\"], \n",
    "        - 1. 首先是将 $x_0$ 输入到 embedding 层：$ input_t^e= embedding(x_t)$\n",
    "        - 2. 接下来初始化 $h_0$, $h_0$ 是一个全零向量\n",
    "        - 3. 将生成的 $ input_t^e$ 和 $h_0$ 输入到 RNN模型内，获得全新的$h_1$， $h_1 = RNN(input_t^e, h_0)$\n",
    "        - 4. 依次操作，并且将$h_1,h_2,...,h_T$保存好作为下面attention机制需要的部分\n",
    "    \n",
    "    - 2. decoder部分：假设输入是法语序列 Y = [\"<SOS>\",\"Je\",\"t\",\"aime\",\"<EOS>\"]\n",
    "        - 1. 首先要明确几个概念，decoder也是GRU，只不过GRU的输入经过加性attention机制进行修改了\n",
    "            - decoder的输入跟encoder是一样的，时间步s的 $input_s^d$，上一个时刻的隐藏状态 $h_s$\n",
    "        - 2. 基本的过程可以先用语言描述清楚：\n",
    "            - 当s=0，$Y_0=<SOS>$,先计算出来过去的T个$h_i$与$Y_0$之间的相关程度，及注意力得分 $e^s_t$\n",
    "            - 然后将所有 $e^s_t$ 给综合起来，然后归一化为注意力权重\n",
    "            - 生成上下文向量\n",
    "$$\n",
    "\\begin{aligned}\n",
    "e_s^{\\text{dec}} &= \\text{Embedding}(y_{s-1}^{\\text{true}}) \\quad \\in \\mathbb{R}^d \\\\\n",
    "\\bar{e}_s &= \\left[ e_s^{\\text{dec}};\\ c_s \\right] \\quad \\in \\mathbb{R}^{d + 2h} \\\\\n",
    "s_s^{\\text{dec}} &= \\text{GRU}\\left( \\bar{e}_s,\\ s_{s-1}^{\\text{dec}} \\right) \\quad \\in \\mathbb{R}^h \\\\\n",
    "p(y_s \\mid y_{1:s-1}, X) &= \\text{softmax}\\left( W_o \\left[ s_s^{\\text{dec}};\\ c_s \\right] + b_o \\right) \\quad \\in \\mathbb{R}^V\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq 代码实现函数整合\n",
    "\n",
    "- 清理数据\n",
    "    - 统一大小写\n",
    "    - 不要符号\n",
    "    - 控制sentence长度\n",
    "- 创建数据集\n",
    "    - 创建源语言的词库\n",
    "    - 创建目标语言的词库\n",
    "    - 创建pair词对\n",
    "    - 根据词对创建word_tensor，包括text_tensor, target_tensor\n",
    "    - 创建dataloader函数\n",
    "    - 创建随机batch生成函数\n",
    "- 创建encoder和decoder类\n",
    "    - encoder:\n",
    "        - encoder parameters:\n",
    "            - self.embedding_layer\n",
    "            - self.gru_model\n",
    "            - self.hidden_state\n",
    "        - encoder forward:\n",
    "            - embedded = self.embedding_layer(text_tensor)\n",
    "            - output, hidden_state = self.gru_model(embedded, hidden_state)\n",
    "            - return output, hidden_state\n",
    "    - decoder:\n",
    "        - decoder parameters:\n",
    "            - self.hidden_size\n",
    "            - self.output_size\n",
    "            - self.embedding_layer(targt_word_size, hidden_size)\n",
    "            - self.gru_model(hidden_size,hidden_size, batch_first=True)\n",
    "            - self.output_layer(hidden_size, output_size)\n",
    "            - self.dropout(dropout_p)\n",
    "        - decoder forward_step:\n",
    "            - embedded = self.embedding_layer(target_tensor)\n",
    "            - embedded = F.relu(embedded)\n",
    "            - output, hidden_state = self.gru_model(embedded, hidden_state)\n",
    "            - output = self.output_layer(output)\n",
    "            - return output, hidden_state\n",
    "        - decoder forward:\n",
    "            - decoder_hidden_state = encoder_hidden_state\n",
    "            - decoder_input = <SOS>\n",
    "            - decoder_outputs = []\n",
    "            - for i in range(MAX_LENGTH):\n",
    "                - decoder_output, decoder_hidden_state = forward_step(decoder_input, decoder_hidden_state)\n",
    "                - decoder_outputs.append(decoder_output)\n",
    "                    - $t$ time step 产生了 output，更新了hidden_state\n",
    "                - 开始下一轮输入：\n",
    "                    - 如果是训练stage，将 decoder_input = Y[i]\n",
    "                    - 如果不是，则是：\n",
    "                        - _, topi = decoder_output.topk(1)\n",
    "                        - decoder_input = topi.squeeze(-1).detach()\n",
    "            - decoder_outputs = torch.cat(decoder_outputs), # 整合所有输出\n",
    "            - decoder_outputs = F.log_softmax(decoder_outputs), # 这里不理解\n",
    "            - return decoder_outputs, decoder_hidden\n",
    "- 创建训练函数：\n",
    "    - 设置optimizer,criterion\n",
    "    - 设置num_epoch, learning_rate\n",
    "    - for epoch in range(num_epoch):\n",
    "        - 随机获取一个batch的语言对，batch_size=64\n",
    "        - for data in dataLoader: 相当于是在整个数据集上训练\n",
    "            - text_tensor, label_tensor, text, label = pair\n",
    "            - text_tensor, label_tensor = text_tensor.to(device), label_tensor.to(device)\n",
    "            - encoder_outputs, encoder_hidden = encoder(parameters)\n",
    "            - decoder_outputs, decoder_hidden, _ = decoder(encoder_outputs, encoder_hidden,label_tensor)\n",
    "            - 计算loss， loss = criterion(label_tensor,decoder_outputs)\n",
    "            - 反向传播, loss.backward()\n",
    "            - 更新参数, encoder_optimizer.step(), decoder_optimizer.step()\n",
    "            - 累加损失，total_loss += loss.item()\n",
    "            - 损失取平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 整体代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题：\n",
    "1. `all_letters = string.ascii_letters + \" .,;'-\"`，所有的字符都是这些吗？那么中文字符怎么办\n",
    "2. `unicodeToAscii(s)`，这个函数的具体步骤该如何理解？\n",
    "3. `re.sub`，re的配词方式？\n",
    "4. `open(\"data/%s-%s.txt\" % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')`，为何要有这么多操作\n",
    "5. `pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]`，具体是怎么实现的\n",
    "6. `filterPairs(pairs)`，算法实现太恶心，我还是改成比较好看的\n",
    "7. 其实数据处理这个部分完全可以写成专门的class\n",
    "8. BahdanauAttention的机制现在才搞懂：\n",
    "    - 注意力机制的输入参数有：当前时间s的decoder hidden，过去T时间步的encoder_outputs\n",
    "    - encoder_outputs shape = (batch_size, seq_len, hidden_size)， 就是说包含有seq_len个hidden_state\n",
    "    - 最终生成的上下文向量context vector有点类似于之前的encoder_hidden\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 11464 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4625\n",
      "eng 2986\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.FloatTensor{[1, 1, 64, 128]}, size=[-1, 10, -1]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 343\u001b[0m\n\u001b[1;32m    340\u001b[0m encoder \u001b[38;5;241m=\u001b[39m GRUencoder(embedding_size\u001b[38;5;241m=\u001b[39minput_lang\u001b[38;5;241m.\u001b[39mn_words, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size, dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    341\u001b[0m decoder \u001b[38;5;241m=\u001b[39m AttnGRUdecoder(embedding_size\u001b[38;5;241m=\u001b[39moutput_lang\u001b[38;5;241m.\u001b[39mn_words, hidden_size\u001b[38;5;241m=\u001b[39mhidden_size, dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 343\u001b[0m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 331\u001b[0m, in \u001b[0;36mTrain\u001b[0;34m(train_dataloader, encoder, decoder, n_epoch, lr, print_every, plot_every)\u001b[0m\n\u001b[1;32m    328\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss()\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epoch):\n\u001b[0;32m--> 331\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "Cell \u001b[0;32mIn[14], line 309\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m    306\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    308\u001b[0m encoder_outputs, encoder_hidden \u001b[38;5;241m=\u001b[39m encoder(input_tensor)\n\u001b[0;32m--> 309\u001b[0m decoder_outputs, decoder_hidden, attention_weigths_list \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(decoder_outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, decoder_outputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),output_tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    312\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 281\u001b[0m, in \u001b[0;36mAttnGRUdecoder.forward\u001b[0;34m(self, encoder_outputs, encoder_hidden, label_tensor)\u001b[0m\n\u001b[1;32m    278\u001b[0m attention_weights_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_LENGTH):\n\u001b[0;32m--> 281\u001b[0m     decoder_output, decoder_hidden, attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     decoder_outputs\u001b[38;5;241m.\u001b[39mappend(decoder_output)\n\u001b[1;32m    283\u001b[0m     attention_weights_list\u001b[38;5;241m.\u001b[39mappend(attention_weights)\n",
      "Cell \u001b[0;32mIn[14], line 260\u001b[0m, in \u001b[0;36mAttnGRUdecoder.Step\u001b[0;34m(self, decoder_input, decoder_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m    258\u001b[0m embedded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_layer(decoder_input)\n\u001b[1;32m    259\u001b[0m embedded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embedded_input)\n\u001b[0;32m--> 260\u001b[0m context_vector, attention_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# 将上下文向量与嵌入向量拼接\u001b[39;00m\n\u001b[1;32m    263\u001b[0m rnn_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([embedded_input\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m), context_vector], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py10/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[14], line 227\u001b[0m, in \u001b[0;36mBahdanauAttention.forward\u001b[0;34m(self, decoder_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m    224\u001b[0m batch_size, seq_len, hidden_size \u001b[38;5;241m=\u001b[39m encoder_outputs\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# 将解码器隐藏状态扩展为 (batch_size, seq_len, hidden_size)\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m decoder_hidden_expanded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# 对编码器隐藏状态进行线性变换\u001b[39;00m\n\u001b[1;32m    230\u001b[0m encoder_transformed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_h(encoder_outputs)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.cuda.FloatTensor{[1, 1, 64, 128]}, size=[-1, 10, -1]): the number of sizes provided (3) must be greater or equal to the number of dimensions in the tensor (4)"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "import string\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "all_letters = string.ascii_letters + \" .,;'-\" # 所有的字典只有这个吗？\n",
    "n_letters = len(all_letters)\n",
    "MAX_LENGTH = 10\n",
    "eng_prefixes = (\n",
    "    \"i am \", \n",
    "    \"i m \",\n",
    "    \"he is\", \n",
    "    \"he s \",\n",
    "    \"she is\", \n",
    "    \"she s \",\n",
    "    \"you are\", \n",
    "    \"you re \",\n",
    "    \"we are\", \n",
    "    \"we re \",\n",
    "    \"they are\", \n",
    "    \"they re \"\n",
    ")\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self,name):\n",
    "        self.name = name\n",
    "        self.word2index = {} # 全词典唯一\n",
    "        self.index2word = {} # 全词典唯一\n",
    "        self.word2count = {} # 会更改\n",
    "        self.n_words = 0\n",
    "    \n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "# 没理解参数\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    # 调用 unicodeToAscii 并将字符串转换为小写，去除首尾空格\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    # 在标点符号前后添加空格\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    # 将非字母字符替换为空格\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    # 去除多余的空格并返回结果\n",
    "    return s.strip()\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # read the file and split into lines\n",
    "    lines = open(\"data/%s-%s.txt\" % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def filterPair(p):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    - p: 一个包含两个字符串的列表或元组，代表一个句子对\n",
    "    - 功能：\n",
    "        - 检查句子的单词数小于 MAX_LENGTH（即10个单词）\n",
    "        - 检查英语句子（p[1]）是否以 eng_prefixes 中的任何一个前缀开头。\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    \"\"\"\n",
    "    功能：\n",
    "        - 使用列表推导式遍历 pairs 中的每一个句子对，并调用 filterPair 函数进行筛选。\n",
    "        - 返回一个新的列表，其中只包含通过 filterPair 筛选后的句子对。\n",
    "    \"\"\"\n",
    "\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" %len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.add_sentence(pair[0])\n",
    "        output_lang.add_sentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1,-1)\n",
    "\n",
    "def tensorFromPair(input_lang, output_lang, pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, output_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData(\"eng\",\"fra\",True)\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.uint32)\n",
    "    output_ids = np.zeros((n, MAX_LENGTH), dtype=np.uint32)\n",
    "\n",
    "    for idx, (input, output) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang,input)\n",
    "        out_ids = indexesFromSentence(output_lang,output)\n",
    "        inp_ids.append(EOS_token)\n",
    "        out_ids.append(EOS_token)\n",
    "        input_ids[idx,:len(inp_ids)] = inp_ids\n",
    "        output_ids[idx, :len(out_ids)] = out_ids\n",
    "    \n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                                torch.LongTensor(output_ids).to(device))\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader\n",
    "\n",
    "class GRUencoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dropout_p):\n",
    "        super(GRUencoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding_layer = nn.Embedding(self.embedding_size, self.hidden_size)\n",
    "        self.gru_encoder = nn.GRU(self.hidden_size,self.hidden_size,batch_first=True) # batch_size, sequence_length, hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "    def forward(self, input_tensor):\n",
    "        embedded = self.dropout(self.embedding_layer(input_tensor))\n",
    "        encoder_outputs, encoder_hidden = self.gru_encoder(embedded)\n",
    "        return encoder_outputs, encoder_hidden\n",
    "\n",
    "class GRUdecoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dropout_p):\n",
    "        super(GRUdecoder,self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.embedding_layer = nn.Embedding(self.embedding_size, self.hidden_size)\n",
    "        self.gru_decoder = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.output_layer = nn.Linear(self.hidden_size, self.embedding_size)\n",
    "    \n",
    "    def step(self, input_tensor, decoder_hidden):\n",
    "        embedded = self.embedding_layer(input_tensor)\n",
    "        embedded = F.relu(embedded)\n",
    "        decoder_output, decoder_hidden = self.gru_decoder(embedded, decoder_hidden)\n",
    "        decoder_output = self.output_layer(decoder_output)\n",
    "        return decoder_output, decoder_hidden\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, label_tensors=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            if label_tensors is not None: # teacher forcing\n",
    "                decoder_input = label_tensors[:,i].unsqueeze(1)\n",
    "            else:\n",
    "                # 推理阶段 \n",
    "                _, topi = decoder_output.topk(1) # 这个作用至今没搞明白\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "        \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1) # 不是很理解？\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) # 不是很理解这一步\n",
    "        return decoder_outputs, decoder_hidden, None   \n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self,hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W_s = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.W_h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.V   = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param decoder_hidden: 解码器隐藏状态(batch_size, hidden_size)\n",
    "        :param encoder_outputs: 隐藏层所有时间步的隐藏状态(batch_size, seq_len, hidden_size)\n",
    "        :return: context vector (batch_size, hidden_size)和注意力权重(batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, hidden_size = encoder_outputs.size()\n",
    "\n",
    "        # 将解码器隐藏状态扩展为 (batch_size, seq_len, hidden_size)\n",
    "        decoder_hidden_expanded = self.W_s(decoder_hidden).unsqueeze(1).expand(-1,seq_len,-1)\n",
    "\n",
    "        # 对编码器隐藏状态进行线性变换\n",
    "        encoder_transformed = self.W_h(encoder_outputs)\n",
    "\n",
    "        # 计算注意力得分 (batch_size, seq_len, hidden_size)\n",
    "        energy = torch.tanh(decoder_hidden_expanded + encoder_transformed)\n",
    "\n",
    "        # 注意力得分的标量值，(batch_size, seq_len)\n",
    "        attention_scores = self.V(energy).squeeze(2)\n",
    "\n",
    "        # 注意力权重\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)\n",
    "\n",
    "        # 计算上下文向量 (batch_size, hidden_size)\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class AttnGRUdecoder(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, dropout_p):\n",
    "        super(AttnGRUdecoder, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_layer = nn.Embedding(self.embedding_size, self.hidden_size)\n",
    "        self.attention_layer = BahdanauAttention(self.hidden_size)\n",
    "        self.gru_decoder = nn.GRU(self.embedding_size+self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        self.output_layer = nn.Linear(self.hidden_size, self.embedding_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def Step(self, decoder_input, decoder_hidden, encoder_outputs):\n",
    "        embedded_input = self.embedding_layer(decoder_input)\n",
    "        embedded_input = self.dropout(embedded_input)\n",
    "        context_vector, attention_weights = self.attention_layer(decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        # 将上下文向量与嵌入向量拼接\n",
    "        rnn_input = torch.cat([embedded_input.squeeze(1), context_vector], dim=1).unsqueeze(1)\n",
    "\n",
    "        # 更新解码器隐藏状态\n",
    "        decoder_output, decoder_hidden = self.gru_decoder(rnn_input,decoder_hidden)\n",
    "\n",
    "        # 生成输出\n",
    "        output = self.output_layer(decoder_output.squeeze(1))\n",
    "\n",
    "        return output, decoder_hidden, attention_weights\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, label_tensor):\n",
    "        batch_size, seq_len, hidden_size = encoder_outputs.size()\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_outputs = []\n",
    "        attention_weights_list = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attention_weights = self.Step(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attention_weights_list.append(attention_weights)\n",
    "\n",
    "            if label_tensor is not None: # teacher forcing\n",
    "                decoder_input = label_tensor[:,i].unsqueeze(1)\n",
    "            else:\n",
    "                _,topi = decoder_output.top(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "        \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attention_weights_list = torch.stack(attention_weights_list, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attention_weights_list\n",
    "\n",
    "\n",
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        # 已经上device了\n",
    "        input_tensor, output_tensor = data\n",
    "\n",
    "        # 为何要先做一个zero_grad\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, attention_weigths_list = decoder(encoder_outputs, encoder_hidden, output_tensor)\n",
    "\n",
    "        loss = criterion(decoder_outputs.view(-1, decoder_outputs.size(-1)),output_tensor.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def Train(train_dataloader, encoder, decoder, n_epoch, lr, print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_loss = []\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=lr)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print(loss)\n",
    "\n",
    "hidden_size = 128\n",
    "batch_size = 64\n",
    "n_epoch = 80\n",
    "lr = 0.001\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size=batch_size)\n",
    "\n",
    "encoder = GRUencoder(embedding_size=input_lang.n_words, hidden_size=hidden_size, dropout_p=0.1).to(device)\n",
    "decoder = AttnGRUdecoder(embedding_size=output_lang.n_words, hidden_size=hidden_size, dropout_p=0.1).to(device)\n",
    "\n",
    "Train(train_dataloader, encoder, decoder, n_epoch, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 代码数据流展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 模型变体尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
